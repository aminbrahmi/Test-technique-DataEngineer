 Test Technique Data Engineer : DÃ©tection de contenus liÃ©s au harcÃ¨lement

Ce projet vise Ã  dÃ©montrer l'application d'un pipeline de collecte, traitement et visualisation de donnÃ©es sur le thÃ¨me du harcÃ¨lement Ã  partir de Reddit, Twitter et Telegram. Le pipeline inclut le scraping, le prÃ©traitement NLP, l'indexation dans Elasticsearch et la visualisation via Kibana.

âœˆï¸ Objectifs Techniques

-Scraping des rÃ©seaux sociaux : Reddit, Twitter, Telegram

-Stockage NoSQL avec MongoDB

-PrÃ©traitement linguistique (cleaning + NLP)

-Indexation avec Elasticsearch

-Visualisation avec Kibana (ELK stack)

-Conteneurisation via Docker/Docker Compose

-Tests unitaires de validation des scripts

Architecture

Test-technique-DataEngineer/
â”‚
â”œâ”€â”€ config/              # Configuration API (config.ini)
â”œâ”€â”€ scripts/             # Scripts principaux
â”‚   â”œâ”€â”€ scraper.py       # Scraping Reddit, Twitter, Telegram
â”‚   â”œâ”€â”€ preprocessing.py # Nettoyage et lemmatisation
â”‚   â”œâ”€â”€ nlp_pipeline.py  # Langue + sentiment
â”‚   â””â”€â”€ es_ingest.py     # Indexation Elasticsearch
â”‚
â”œâ”€â”€ tests/               # Tests unitaires
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_nlp_pipeline.py
â”‚
â”œâ”€â”€ docs/                # DonnÃ©es et visualisations
â”‚   â”œâ”€â”€ Kibana Dashboard/        # Captures Ã©cran Kibana
â”‚   â”œâ”€â”€ mongo_results.json       # Export MongoDB
â”‚   â””â”€â”€ es_results.json          # Export Elasticsearch
â”‚
â”œâ”€â”€ Dockerfile           # Environnement d'exÃ©cution
â”œâ”€â”€ docker-compose.yml   # Lancement des services
â”œâ”€â”€ requirements.txt     # Librairies Python
â””â”€â”€ README.md            # Documentation actuelle

1. ğŸ’¿ Scraping des donnÃ©es (scripts/scraper.py)

Reddit : via praw, depuis les subreddits bullying, TrueOffMyChest

Twitter (X) : via tweepy et token Bearer

Telegram : via Telethon, accÃ¨s Ã  des groupes publics

Les donnÃ©es sont stockÃ©es dans MongoDB (db: harcelement, collection: posts).

Champs collectÃ©s : title, content, author, date, url, source, processed

2. âš–ï¸ PrÃ©traitement des textes (scripts/preprocessing.py)

Suppression des balises HTML et URLs

Nettoyage (ponctuation, chiffres)

Lemmatisation et suppression des stopwords avec SpaCy

Mise Ã  jour du champ cleaned_content et processed = True

3. ğŸ§  Traitement NLP (scripts/nlp_pipeline.py)

Langue : dÃ©tection via langid

Traduction automatique si besoin avec GoogleTranslator

Sentiment : via TextBlob

Ajout des champs : language, sentiment, sentiment_score

4. âš™ï¸ Indexation Elasticsearch (scripts/es_ingest.py)

Connexion Ã  MongoDB et Elasticsearch

CrÃ©ation d'index harcelement_posts avec mapping personnalisÃ©

Indexation via helpers.bulk

RafraÃ®chissement pour Kibana

Champs indexÃ©s : title, content, author, language, sentiment, sentiment_score, etc.

5. ğŸ“Š Visualisation avec Kibana

Kibana Dashboard (URL: http://localhost:5601)

Contenus du tableau de bord :

Diagramme de rÃ©partition par langue

Diagramme de rÃ©partition par sentiment

Courbe temporelle des publications

Liste des contenus les plus nÃ©gatifs

Filtres dynamiques : langue, source, date

ğŸ“š Choix techniques

MongoDB pour le stockage NoSQL (souplesse de structure)

Elasticsearch pour l'indexation rapide et recherches avancÃ©es

TextBlob + GoogleTranslator : facile Ã  intÃ©grer pour de l'analyse de sentiment rapide

Docker Compose : isolation de chaque service (Mongo, ES, Kibana, Scraper)


ğŸ”§ Lancement manuel

# Scraping
docker exec -it scraper python scripts/scraper.py

# Nettoyage
docker exec -it scraper python scripts/preprocessing.py

# NLP
docker exec -it scraper python scripts/nlp_pipeline.py

# Indexation
python scripts/es_ingest.py


ğŸ“š Tests unitaires (dossier /tests)

test_scraper.py : vÃ©rifie que les fonctions Reddit/Telegram sont appelables

test_preprocessing.py : vÃ©rifie le nettoyage du texte

test_nlp_pipeline.py : vÃ©rifie la langue et le sentiment

ğŸ’¾ Export des donnÃ©es

MongoDB : docs/mongo_results.json

Elasticsearch : docs/es_results.json

Les fichiers se trouvent dans le dossier docs/

Les captures dâ€™Ã©cran du tableau de bord Kibana dans docs/Kibana Dashboard/